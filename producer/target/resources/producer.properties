#identifikator pripojeni. Je nutne vyjhmenovat nekolik serveru pro pripojeni na server. Urcite neni nutne vyjmenovavt vsechny. Jde o pocatecne spojeni.
bootstrap.servers=localhost:9093
#bootstrap.servers=vm011-kafka.test.ris.local:9095,vm011-kafka.test.ris.local:9096,vm011-kafka.test.ris.local:9097
#dulezitý atribut z pohledu governancea. Identifikuje konkrétní klienta kafky. Zde je potreba aby kazdý klient mel sve unikátní jméno/identifikaci.
#jeden producer muze byt pouyit pro vicero kafka TOPIC.
client.id=DemoProducer
#ack = acknowledge zpráva bude mít status odeslana kdyz bude zkopírováná do vsech replikaci 
acks=all
#pocet pokusu pro odeslání maximální cislo je 2147483647
retries=2
#po\u010Drz púokusu pro odeslani zpravy ma vliv na jejich poradi. Kdyz nam yaleyi na poradi musine nasledujici parametr nastavit na 1. V pripade ye nam neyaleyi muzeme nastavit na vyssi hodnotu.
max.in.flight.requests.per.connectio=1
#komprese data - nastavené ted zadne
compression.type=none
#velikost jedné message transakce. Producer zabalí nekolik zpráv do jedné a odesle je jako celek na server. Ak je nutne poslat okamzite kazdou zravu nastavit na velikost jedne zpravy
batch.size=16384
#dalsi paramter pro optimalizaci komunikace na server kafka - tento parameter nastavuje jak casto se ma komunikovat ze strany producenta na servr kafky. Tady plati co nastane driv. Linger.ms nebo barch size.
linger.ms=1
#velikost pameti pro zpravy. Producent muze pracovat rychleji nez odesila. Po dosayeni maxima producent dostane vyjimku (Exception)
#uvedena hodnota je default neni nutne ji menit.
buffer.memory=33554432
#uzavreni idle spojeni. Aktualne 5 min.
connections.max.idle.ms=300000
#doba cekani na od odeslani zpravy po prijeti acknowledge. Default je 2 min. Je nutne prizpusobit charakteru zpravy a jeji platnosti
delivery.timeout.ms=120000
#doba pro odelsani zpravy na server a ziskani odpovedi ze serveru. (Pozor neni to potvrzeni). tetni argument se pouzíva pro rizeni opakovani odeslani zpravy. Default je 30 sekund.
request.timeout.ms=30000

#data se serializuji do pole bajtu. Kafka presi jen pole bnajtu zadny jiny format nepodporu. Proto je nutne mit definvany serializer, ktery se data spravne budou serializovat.
#serializace klice. Klic je dulezity pro rychlo identifikaci konkretni zpravy., Nezamenovat s messageId, ktere je v hlavicce zpravya  generuje se automaticky. Jednim z pouziti je v pripade pozadavku na compaction. 
#Znamena to ze v Kafka topic budou jen posledni aktulani data. Kafka identifikuje zpravu podle klice a zanecha jen s nejvyssi casovou znackou.
# V pripade ze nam zalezi na poradi zprav tak klic je nezbatnou soucasti kazde zpravy. 
key.serializer=org.apache.kafka.common.serialization.StringSerializer
#serializace pro telo(body) zpravy
value.serializer=org.apache.kafka.common.serialization.StringSerializer

# For SSL
security.protocol=SSL
ssl.protoco=TLSv1.2
ssl.truststore.location=./resources/demo.client.truststore.jks
ssl.truststore.password=test1234

# For SSL auth
ssl.keystore.location=./resources/demo.client.keystore.jks
ssl.keystore.password=test1234
ssl.key.password=test1234

ssl.keystore.type=PKCS12
ssl.truststore.type=JKS
